{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03f14893",
   "metadata": {},
   "source": [
    "### üìä Customer Churn ‚Äì Model Training & Evaluation\n",
    "\n",
    "This notebook builds and evaluates machine learning models to predict customer churn. It includes:\n",
    "\n",
    "- Importing the preprocessed dataset  \n",
    "- Splitting into training and test sets  \n",
    "- Training baseline models (Logistic Regression, Random Forest, XGBoost)  \n",
    "- Evaluating performance using metrics  \n",
    "- Interpreting feature importance  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "715325b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (86, 30), Test set: (22, 30)\n"
     ]
    }
   ],
   "source": [
    "# üì• Load cleaned dataset and split for training\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load preprocessed dataset\n",
    "df = pd.read_csv(\"../data/customer_churn_cleaned.csv\")\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(\"Churn_Yes\", axis=1)\n",
    "y = df[\"Churn_Yes\"]\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Confirm shape\n",
    "print(f\"Train set: {X_train.shape}, Test set: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5138d9",
   "metadata": {},
   "source": [
    "## ü§ñ Train Logistic Regression Model\n",
    "\n",
    "In this section, we train a baseline Logistic Regression model on the processed customer churn dataset.\n",
    "\n",
    "We evaluate the model's performance using:\n",
    "- Accuracy\n",
    "- Confusion matrix\n",
    "- Classification report (Precision, Recall, F1-score)\n",
    "\n",
    "This provides a benchmark to compare with more advanced models like XGBoost or Random Forest.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dbdbc8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîé Logistic Regression Evaluation\n",
      "Accuracy: 0.4090909090909091\n",
      "\n",
      "Confusion Matrix:\n",
      " [[3 8]\n",
      " [5 6]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.38      0.27      0.32        11\n",
      "        True       0.43      0.55      0.48        11\n",
      "\n",
      "    accuracy                           0.41        22\n",
      "   macro avg       0.40      0.41      0.40        22\n",
      "weighted avg       0.40      0.41      0.40        22\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# ü§ñ Train Logistic Regression model\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Initialize and train model\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "\n",
    "# üìä Evaluate performance\n",
    "print(\"üîé Logistic Regression Evaluation\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_lr))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_lr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d096a9",
   "metadata": {},
   "source": [
    "## ‚ö° Train XGBoost Model\n",
    "\n",
    "In this step, we train an XGBoost classifier to predict customer churn. XGBoost is a powerful gradient boosting algorithm known for its performance and speed.\n",
    "\n",
    "We‚Äôll compare its results with our Logistic Regression baseline using:\n",
    "- Accuracy\n",
    "- Confusion matrix\n",
    "- Classification report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4298103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç XGBoost Evaluation\n",
      "Accuracy: 0.6363636363636364\n",
      "\n",
      "Confusion Matrix:\n",
      " [[6 5]\n",
      " [3 8]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       False       0.67      0.55      0.60        11\n",
      "        True       0.62      0.73      0.67        11\n",
      "\n",
      "    accuracy                           0.64        22\n",
      "   macro avg       0.64      0.64      0.63        22\n",
      "weighted avg       0.64      0.64      0.63        22\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.python/current/lib/python3.12/site-packages/xgboost/training.py:183: UserWarning: [17:27:02] WARNING: /workspace/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "# ‚ö° Train and Evaluate XGBoost Model\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Initialize and train the model\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# üß† Evaluate performance\n",
    "print(\"üîç XGBoost Evaluation\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_xgb))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_xgb))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923722ed",
   "metadata": {},
   "source": [
    "## ‚úÖ Final Model Comparison Summary\n",
    "\n",
    "We trained and evaluated two classification models on the preprocessed customer churn dataset:\n",
    "\n",
    "| Model               | Accuracy | Precision (avg) | Recall (avg) | F1-score (avg) |\n",
    "|--------------------|----------|------------------|--------------|----------------|\n",
    "| Logistic Regression| 0.41     | 0.40             | 0.41         | 0.40           |\n",
    "| XGBoost            | 0.64     | 0.64             | 0.63         | 0.63           |\n",
    "\n",
    "üîç **Conclusion**:  \n",
    "XGBoost outperformed Logistic Regression in all evaluation metrics. We recommend using XGBoost for production deployment or further hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0119864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DeviceProtection_Yes</td>\n",
       "      <td>0.098697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>StreamingMovies_No internet service</td>\n",
       "      <td>0.081416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>StreamingTV_No internet service</td>\n",
       "      <td>0.077740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DeviceProtection_No internet service</td>\n",
       "      <td>0.077368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>OnlineBackup_Yes</td>\n",
       "      <td>0.070418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>InternetService_No</td>\n",
       "      <td>0.059230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>InternetService_Fiber optic</td>\n",
       "      <td>0.054407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>TechSupport_No internet service</td>\n",
       "      <td>0.052591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MultipleLines_No phone service</td>\n",
       "      <td>0.046674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>StreamingMovies_Yes</td>\n",
       "      <td>0.039845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Feature  Importance\n",
       "17                  DeviceProtection_Yes    0.098697\n",
       "22   StreamingMovies_No internet service    0.081416\n",
       "20       StreamingTV_No internet service    0.077740\n",
       "16  DeviceProtection_No internet service    0.077368\n",
       "15                      OnlineBackup_Yes    0.070418\n",
       "11                    InternetService_No    0.059230\n",
       "10           InternetService_Fiber optic    0.054407\n",
       "18       TechSupport_No internet service    0.052591\n",
       "8         MultipleLines_No phone service    0.046674\n",
       "23                   StreamingMovies_Yes    0.039845"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# üì§ Export Feature Importances from XGBoost\n",
    "import pandas as pd\n",
    "\n",
    "# Create DataFrame with feature names and their importances\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Importance': xgb_model.feature_importances_\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Export to CSV inside the data folder\n",
    "importance_df.to_csv('../data/feature_importance.csv', index=False)\n",
    "\n",
    "# Display the top 10 features for verification\n",
    "importance_df.head(10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
